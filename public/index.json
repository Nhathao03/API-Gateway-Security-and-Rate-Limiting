[
{
	"uri": "//localhost:1313/3-configcognito/3.3-authenticationandstorage/",
	"title": "API Gateway Security and Rate Limiting",
	"tags": [],
	"description": "",
	"content": "Work with Amazon API Gateway Security and Rate Limiting - Session Manager Overall In this lab, you\u0026rsquo;ll learn the basics and practice of Amazon API Gateway Security and Rate Limiting - Session Manager . Perform creating public and private instance connections.\n"
},
{
	"uri": "//localhost:1313/3-configcognito/3.4-accesslevel/",
	"title": "API Gateway Security and Rate Limiting",
	"tags": [],
	"description": "",
	"content": "Work with Amazon API Gateway Security and Rate Limiting - Session Manager Overall In this lab, you\u0026rsquo;ll learn the basics and practice of Amazon API Gateway Security and Rate Limiting - Session Manager . Perform creating public and private instance connections.\n"
},
{
	"uri": "//localhost:1313/",
	"title": "API Gateway Security and Rate Limiting",
	"tags": [],
	"description": "",
	"content": "Work with Amazon API Gateway Security and Rate Limiting - Session Manager Overall In this lab, you\u0026rsquo;ll learn the basics and practice of Amazon API Gateway Security and Rate Limiting - Session Manager . Perform creating public and private instance connections.\n"
},
{
	"uri": "//localhost:1313/2-deloydatabase/2.1-createdynamodbtable/",
	"title": "Create DynamoDB table",
	"tags": [],
	"description": "",
	"content": "CREATE DYNAMODB TABLE Open DynamoDB console Click Create table Enter table name: Documents Enter Parition key is user_id Enter Sort key is file In Table setting section, select Customsize setting Keep DynamoDB Standard for Table class Select On-demand for Capacity mode Scroll to the bottom of the page, click Create table "
},
{
	"uri": "//localhost:1313/2-deloydatabase/2.2-createlambdafunctions/2.2.1-createlistingfunction/",
	"title": "Create listing function",
	"tags": [],
	"description": "",
	"content": "In this section we will create a function to list the documents stored in the DynamoDB table by the user‚Äôs id.\nOpen AWS Lambda console Click Create function Enter function name: list_documents Select Python 3.9 for Runtime Click Create function Enter the following code for the lambda_function.py file: import json import boto3 import os from decimal import * from boto3.dynamodb.types import TypeDeserializer dynamodb = boto3.client(\u0026#39;dynamodb\u0026#39;) serializer = TypeDeserializer() class DecimalEncoder(json.JSONEncoder): def default(self, obj): if isinstance(obj, Decimal): return str(obj) return json.JSONEncoder.default(self, obj) def deserialize(data): if isinstance(data, list): return [deserialize(v) for v in data] if isinstance(data, dict): try: return serializer.deserialize(data) except TypeError: return {k: deserialize(v) for k, v in data.items()} else: return data def lambda_handler(event, context): table_name = os.environ[\u0026#39;TABLE_NAME\u0026#39;] user_id = event[\u0026#39;pathParameters\u0026#39;][\u0026#39;id\u0026#39;] print(user_id) docs = dynamodb.query( TableName=table_name, KeyConditionExpression=\u0026#34;user_id = :id\u0026#34;, ExpressionAttributeValues={ \u0026#34;:id\u0026#34;: { \u0026#39;S\u0026#39;: user_id } } ) format_data_docs = deserialize(docs[\u0026#34;Items\u0026#34;]) # TODO implement return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;headers\u0026#34;: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Access-Control-Allow-Methods\u0026#34;: \u0026#34;GET,PUT,POST,DELETE, OPTIONS\u0026#34;, \u0026#34;Access-Control-Allow-Headers\u0026#34;: \u0026#34;Access-Control-Allow-Headers, Origin,Accept, X-Requested-With, Content-Type, Access-Control-Request-Method,X-Access-Token,XKey,Authorization\u0026#34; }, \u0026#34;body\u0026#34;: json.dumps(format_data_docs, cls=DecimalEncoder) } Then click Deloy The above code executes to get the user‚Äôs TABLE_NAME and id environment variables from the event. Then query to the DynamoDB table provided that the value of Partition key is equal to the user‚Äôs id. Then reformat the data returned after the query.\nWe need to add an environment variable to the function. Click the Configuration tab, then select Environment variables in the left menu. Press Edit Click Add environment variable Enter TABLE_NAME as key Enter the DynamoDB table name that you just created Click Save Next, add permissions for function to access DynamoDB table Click Permission on the left menu Click on the execution role of the function Expand the AWSLambdaBasicExecutionRole‚Ä¶ policy, then click Edit Click JSON. Copy the JSON below into the editor ,\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;dynamodb:Query\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:REGION:ACCOUNT_ID:table/Documents\u0026#34;\r} Replace REGION and ACCOUNT_ID with the region you create the table and your account id.\nClick Review policy Click Save changes "
},
{
	"uri": "//localhost:1313/3-configcognito/3.1-introduceamplify/",
	"title": "Introduce Amplify",
	"tags": [],
	"description": "",
	"content": "Overview AWS Amplify is a toolset that helps developers quickly build and deploy web and mobile applications integrated with AWS services such as API, Authentication, Storage, and Hosting. Amplify simplifies backend management, provides frontend libraries, and offers ready-to-use hosting services for production applications.\nAuthentication with Amplify Authentication with Amplify makes it easy to integrate user authentication features into applications using Amazon Cognito as the backend. It supports sign-up, sign-in, forgot password, multi-factor authentication (MFA), and social sign-in (Google, Facebook, Apple), allowing developers to quickly implement secure user management.\nStorage with Amplify Storage with Amplify provides a solution for storing files (images, videos, documents) via Amazon S3. Data can be managed with privacy controls (public, protected, private), integrated with user authentication to control access, and supports secure file upload, download, and sharing.\n"
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Gi·ªõi thi·ªáu ƒë·ªÅ t√†i Trong b·ªëi c·∫£nh c√°c h·ªá th·ªëng hi·ªán ƒë·∫°i ng√†y c√†ng ph·ª• thu·ªôc v√†o API ƒë·ªÉ giao ti·∫øp gi·ªØa c√°c d·ªãch v·ª•, vi·ªác ƒë·∫£m b·∫£o an to√†n cho c√°c API tr·ªü th√†nh m·ªôt nhi·ªám v·ª• thi·∫øt y·∫øu. M·ªôt API kh√¥ng ƒë∆∞·ª£c b·∫£o v·ªá ƒë√∫ng c√°ch c√≥ th·ªÉ tr·ªü th√†nh ƒëi·ªÉm y·∫øu khi·∫øn c·∫£ h·ªá th·ªëng b·ªã t·∫•n c√¥ng, g√¢y m·∫•t d·ªØ li·ªáu, gi√°n ƒëo·∫°n d·ªãch v·ª• ho·∫∑c vi ph·∫°m tu√¢n th·ªß b·∫£o m·∫≠t.\nƒê·ªÅ t√†i ‚ÄúAPI Security Gateway v·ªõi Advanced Protection‚Äù h∆∞·ªõng ƒë·∫øn vi·ªác tri·ªÉn khai m·ªôt ki·∫øn tr√∫c API Gateway b·∫£o m·∫≠t cao c·∫•p tr√™n n·ªÅn t·∫£ng AWS, t√≠ch h·ª£p ƒë·∫ßy ƒë·ªß c√°c l·ªõp b·∫£o v·ªá hi·ªán ƒë·∫°i v√† quy chu·∫©n an ninh, bao g·ªìm:\nThreat Protection: B·∫£o v·ªá ch·ªëng l·∫°i c√°c cu·ªôc t·∫•n c√¥ng nh∆∞ DDoS, SQL injection, XSS\u0026hellip; Rate Limiting: Gi·ªõi h·∫°n t·ªëc ƒë·ªô truy c·∫≠p API theo IP ho·∫∑c theo ng∆∞·ªùi d√πng. Authentication: C∆° ch·∫ø x√°c th·ª±c m·∫°nh m·∫Ω, h·ªó tr·ª£ OAuth2, JWT, SSO\u0026hellip; Authorization: Ph√¢n quy·ªÅn chi ti·∫øt theo vai tr√≤, nh√≥m ng∆∞·ªùi d√πng. Monitoring \u0026amp; Logging: Gi√°m s√°t th·ªùi gian th·ª±c, alert, truy v·∫øt s·ª± c·ªë. Operational Readiness: Tri·ªÉn khai, b·∫£o tr√¨ v√† qu·∫£n l√Ω v·∫≠n h√†nh thu·∫≠n ti·ªán. Developer Integration: H·ªó tr·ª£ t·ªët cho vi·ªác t√≠ch h·ª£p frontend/backend v√† CI/CD. M·ª•c ti√™u tri·ªÉn khai H∆∞·ªõng d·∫´n s·∫Ω t·∫≠p trung v√†o vi·ªác c·∫•u h√¨nh v√† tri·ªÉn khai c√°c d·ªãch v·ª• native c·ªßa AWS ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c c√°c y√™u c·∫ßu sau:\nY√™u c·∫ßu k·ªπ thu·∫≠t D·ªãch v·ª• s·ª≠ d·ª•ng tr√™n AWS Threat Protection AWS Shield, AWS WAF DNS Protection + Entry Point Amazon Route 53 API Gateway Management Amazon API Gateway Authentication / Authorization Amazon Cognito, JWT, IAM Rate Limiting AWS WAF Rate-based rules, API Gateway quotas Business Logic AWS Lambda Data Storage Amazon S3, DynamoDB, Aurora Serverless Monitoring / Alerting Amazon CloudWatch, X-Ray Ki·∫øn tr√∫c h·ªá th·ªëng H·ªá th·ªëng ƒë∆∞·ª£c thi·∫øt k·∫ø theo h∆∞·ªõng zero-trust, v·ªõi c√°c l·ªõp b·∫£o v·ªá theo chi·ªÅu s√¢u t·ª´ l·ªõp bi√™n (network) ƒë·∫øn ·ª©ng d·ª•ng v√† d·ªØ li·ªáu.\nN·ªôi dung blog g·ªìm 3 ph·∫ßn ch√≠nh Gi·ªõi thi·ªáu ƒë·ªÅ t√†i (b·∫°n ƒëang xem) H∆∞·ªõng d·∫´n tri·ªÉn khai chi ti·∫øt tr√™n AWS Console: C·∫•u h√¨nh t·ª´ng th√†nh ph·∫ßn nh∆∞ Shield, WAF, Cognito, API Gateway, v.v. K·∫øt n·ªëi v√† t√≠ch h·ª£p gi·ªØa c√°c d·ªãch v·ª•. D·ªçn d·∫πp t√†i nguy√™n sau tri·ªÉn khai: H∆∞·ªõng d·∫´n x√≥a c√°c d·ªãch v·ª• ƒë√£ s·ª≠ d·ª•ng ƒë·ªÉ tr√°nh ph√°t sinh chi ph√≠. Y√™u c·∫ßu tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu M·ªôt t√†i kho·∫£n AWS v·ªõi quy·ªÅn qu·∫£n tr·ªã ho·∫∑c IAM ƒë·ªß quy·ªÅn thao t√°c. Ki·∫øn th·ª©c c∆° b·∫£n v·ªÅ REST API, b·∫£o m·∫≠t web (JWT, OAuth2, IAM). M·ªôt t√™n mi·ªÅn n·∫øu b·∫°n mu·ªën c·∫•u h√¨nh v·ªõi Route 53 v√† CloudFront. C√†i ƒë·∫∑t s·∫µn AWS CLI n·∫øu mu·ªën thao t√°c k·∫øt h·ª£p terminal. K·∫øt lu·∫≠n H∆∞·ªõng d·∫´n n√†y ph√π h·ª£p cho c·∫£:\nNh√† ph√°t tri·ªÉn ƒëang x√¢y d·ª±ng h·ªá th·ªëng API tr√™n AWS DevOps ho·∫∑c Security Engineer tri·ªÉn khai m√¥ h√¨nh b·∫£o m·∫≠t ph√¢n l·ªõp H·ªçc vi√™n ho·∫∑c k·ªπ s∆∞ mu·ªën t√¨m hi·ªÉu ki·∫øn tr√∫c b·∫£o m·∫≠t API hi·ªán ƒë·∫°i "
},
{
	"uri": "//localhost:1313/3-configcognito/3.2-preparation/",
	"title": "API Gateway Security and Rate Limiting",
	"tags": [],
	"description": "",
	"content": "We perform the following steps to prepare for authentication and save files with the Amplify library in the following section:\nTo install Amplify CLI, run the command below: npm install -g @aws-amplify/cli You must install NodeJs before installing Amplify CLI You should create a user and configure an AWS profile with credentials on your machine.\nRun the below commands to clone the application to your device: git clone https://github.com/AWS-First-Cloud-Journey/FCJ-Serverless-DMS\rcd FCJ-Serverless-DMS\rnpm install Open the project and open src/component/Home/Upload.js file. Comment the block codes that call API to interact with DynamoDB To initialize Amplify for your application, run the following command from the application‚Äôs root directory:\nEnter the following information:\n? Enter a name for the project `fcjdms`` The following configuration will be applied:\nProject information | Name: fcjdms | Environment: dev | Default editor: Visual Studio Code | App type: javascript | Javascript framework: react | Source Directory Path: src | Distribution Directory Path: build | Build Command: npm run-script build | Start Command: npm run-script start\n? Initialize the project with the above configuration? Yes Using default provider awscloudformation ? Select the authentication method you want to use: AWS profile\nFor more information on AWS Profiles, see: https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-profiles.html\n? Please choose the profile you want to use default ? Help improve Amplify CLI by sharing non sensitive configurations on failures (y/N) ‚Ä∫ No\n"
},
{
	"uri": "//localhost:1313/2-deloydatabase/2.2-createlambdafunctions/2.2.2-createcreatingfunction/",
	"title": "Create creating function",
	"tags": [],
	"description": "",
	"content": "This section will create a function to add document information stored in the DynamoDB table.\nOpen AWS Lambda console Click Create function Enter function name: upload_document Select Python 3.9 for Runtime Click Create function Enter the following code for the lambda_function.py file: import json import boto3 import os from datetime import datetime, timezone dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) def lambda_handler(event, context): table_name = os.environ[\u0026#39;TABLE_NAME\u0026#39;] now = datetime.now(tz=timezone.utc) dt_string = now.strftime(\u0026#34;%d/%m/%Y %H:%M:%S\u0026#34;) #doc_data = json.loads(event[\u0026#34;body\u0026#34;]) doc_data = event[\u0026#34;body\u0026#34;] path = \u0026#34;protected/{}/{}\u0026#34;.format(doc_data[\u0026#39;identityId\u0026#39;], doc_data[\u0026#39;file\u0026#39;]) doc_data.update({\u0026#34;path\u0026#34;: path, \u0026#34;modified\u0026#34;: dt_string}) table = dynamodb.Table(table_name) table.put_item(Item = doc_data) # TODO implement return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;successfully upload!\u0026#39;, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#34;Access-Control-Allow-Headers\u0026#34;: \u0026#34;Access-Control-Allow-Headers, Origin, Accept, X-Requested-With, Content-Type, Access-Control-Request-Method,X-Access-Token, XKey, Authorization\u0026#34;, \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Access-Control-Allow-Methods\u0026#34;: \u0026#34;GET,PUT,POST,DELETE,OPTIONS\u0026#34; } } Then click Deloy The above code executes to get the user‚Äôs TABLE_NAME and id environment variables from the event. Then query to the DynamoDB table provided that the value of Partition key is equal to the user‚Äôs id. Then reformat the data returned after the query.\nWe need to add an environment variable to the function. Click the Configuration tab, then select Environment variables in the left menu. Press Edit Click Add environment variable Enter TABLE_NAME as key Enter the DynamoDB table name that you just created Click Save Next, add permissions for function to access DynamoDB table Click Permission on the left menu Click on the execution role of the function Expand the AWSLambdaBasicExecutionRole‚Ä¶ policy, then click Edit Click JSON. Copy the JSON below into the editor ,\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;dynamoDB:PutItem\u0026#34;,\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:REGION:ACCOUNT_ID:table/Documents\u0026#34;\r} Replace REGION and ACCOUNT_ID with the region you create the table and your account id.\nClick Review policy Click Save changes "
},
{
	"uri": "//localhost:1313/2-deloydatabase/2.2-createlambdafunctions/",
	"title": "Create Lambda function",
	"tags": [],
	"description": "",
	"content": "Content Create listing function Create creating function Create deleting function "
},
{
	"uri": "//localhost:1313/2-deloydatabase/",
	"title": "Deloy database",
	"tags": [],
	"description": "",
	"content": "Content Create DynamoDB table Build and push image docker ECS Task Definition "
},
{
	"uri": "//localhost:1313/3-configcognito/",
	"title": "Config Cognito",
	"tags": [],
	"description": "",
	"content": "Overview In this series, we will use the Amplify library to authenticate users with Amazon Cognito, uploading files to the S3 bucket.\nContent Preparation Authentication and Storage Access level "
},
{
	"uri": "//localhost:1313/2-deloydatabase/2.2-createlambdafunctions/2.2.3-createdeletingfunction/",
	"title": "Create deleting function",
	"tags": [],
	"description": "",
	"content": "In this section, we will create a function to delete document information stored in the DynamoDB table by user id and filename.\nOpen AWS Lambda console Click Create function Enter function name: delete_documents Select Python 3.9 for Runtime Click Create function Enter the following code for the lambda_function.py file: import json import boto3 import os client = boto3.resource(\u0026#39;dynamodb\u0026#39;) def lambda_handler(event, context): # TODO implement table_name = os.environ[\u0026#39;TABLE_NAME\u0026#39;] error = None doc_pk = event[\u0026#39;pathParameters\u0026#39;][\u0026#39;id\u0026#39;] print(\u0026#34;doc_pk \u0026#34;, doc_pk) doc_sk = event[\u0026#39;queryStringParameters\u0026#39;][\u0026#39;file\u0026#39;] print(\u0026#34;doc_sk \u0026#34;, doc_sk) table = client.Table(table_name) key = { \u0026#39;user_id\u0026#39;:doc_pk, \u0026#39;file\u0026#39;: doc_sk } try: table.delete_item(Key = key) except Exception as e: error = e except Exception as e: error = e if error is None: message = \u0026#39;delete document successful!\u0026#39; else: print(error) message = \u0026#39;delete document fail\u0026#39; return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: message, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, } Then click Deloy The above code executes to get the user‚Äôs TABLE_NAME and id environment variables from the event. Then query to the DynamoDB table provided that the value of Partition key is equal to the user‚Äôs id. Then reformat the data returned after the query.\nWe need to add an environment variable to the function. Click the Configuration tab, then select Environment variables in the left menu. Press Edit Click Add environment variable Enter TABLE_NAME as key Enter the DynamoDB table name that you just created Click Save Next, add permissions for function to access DynamoDB table Click Permission on the left menu Click on the execution role of the function Expand the AWSLambdaBasicExecutionRole‚Ä¶ policy, then click Edit Click JSON. Copy the JSON below into the editor ,\r{\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;dynamodb:DeleteItem\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:REGION:ACCOUNT_ID:table/Documents\u0026#34;\r} Replace REGION and ACCOUNT_ID with the region you create the table and your account id.\nClick Review policy Click Save changes "
},
{
	"uri": "//localhost:1313/2-deloydatabase/2.3-testlambdafunctions/",
	"title": "Test lambda function",
	"tags": [],
	"description": "",
	"content": "In this section we will create tests to see if the functions are working properly.\nTo test the functions, download the following file to your computer and run the command: aws dynamodb batch-write-item --request-items file://documentData.json\nüìé Document Data\ndocumentData.json (3 KB) Test listing function Open the list_documents function console Click Test tab Enter tc_1 for event name Enter the below json for Event JSON { \u0026#34;pathParameters\u0026#34;: {\r\u0026#34;id\u0026#34;: \u0026#34;abcd1234\u0026#34;\r}\r} Click Save, then click Test You will get all the information of the user\u0026rsquo;s files with the id abcd1234 Test creating function Open the upload_document function console Click Test tab Enter tc_1 for event name Enter the below json for Event JSON {\r\u0026#34;body\u0026#34;:{\r\u0026#34;user_id\u0026#34;: \u0026#34;abcd1234\u0026#34;,\r\u0026#34;file\u0026#34;: \u0026#34;aws_serverless.doc\u0026#34;,\r\u0026#34;folder\u0026#34;: \u0026#34;\u0026#34;,\r\u0026#34;identityId\u0026#34;: \u0026#34;123456cvbn\u0026#34;,\r\u0026#34;modified\u0026#34;: \u0026#34;13-03-2023\u0026#34;,\r\u0026#34;size\u0026#34;: \u0026#34;2MB\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;doc\u0026#34;,\r\u0026#34;tag\u0026#34;: \u0026#34;aws, serverless\u0026#34;\r}\r} Click Save, then click Test You will get a return result of succeeded Open Documents table to check if added successfully Test deleting function Open the delete_documents function console Click Test tab Enter tc_1 for event name Enter the below json for Event JSON {\r\u0026#34;pathParameters\u0026#34;: {\r\u0026#34;id\u0026#34;: \u0026#34;abcd1234\u0026#34;\r},\r\u0026#34;queryStringParameters\u0026#34;: {\r\u0026#34;file\u0026#34;: \u0026#34;aws-exports.js\u0026#34;\r}\r} Click Save, then click Test You will get a return result of succeeded Open Documents table to check if added successfully You are done creating Lambda functions that interact with DynamoDB. In the next post we will authenticate to the archive with the Amplify library.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]